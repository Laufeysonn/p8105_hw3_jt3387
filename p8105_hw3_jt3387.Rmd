---
title: "p8105_hw3_jt3387"
output: github_document
---
  
```{r, message = FALSE}
library(tidyverse)
library(p8105.datasets)
```

## Problem 1

Load the dataset:

```{r}
data("instacart")
instacart = instacart %>% 
  as_tibble(instacart)
```
  
Brief discription of the dataset:

- This dataset contains `r nrow(instacart)` rows and `r ncol(instacart)` columns.

- The dataset contains following variables: ``r names(instacart)``, and some key variables are: `order_id` represents the order identifier, `product_id` represents the product identifier, `user_id` represents the customer identifier, `aisle_id` represents the aisle identifier, `department_id` represents the department identifier.
  
- In total, there are `r instacart %>% select(product_id) %>% distinct %>% count` products found in `r instacart %>% select(user_id, order_id) %>% distinct %>% count` orders from `r instacart %>% select(user_id) %>% distinct %>% count` distinct users.

How many aisles are there, and which aisles are the most items ordered from?

```{r}
instacart %>% 
  count(aisle) %>% 
  arrange(desc(n))
```

- In total, there are 134 aisles, and fresh vegetables and fresh fruits aisles are the most items ordered from.

Make a plot that shows the number of items ordered in each aisle.

```{r}
instacart %>% 
  count(aisle) %>% 
  filter(n > 10000) %>% 
  mutate(aisle = fct_reorder(aisle, n)) %>% 
  ggplot(aes(x = aisle, y = n)) + 
  geom_point() + 
  labs(title = "Number of items ordered in each aisle") +
  theme(axis.text.x = element_text(angle = 60, hjust = 1))
```

Make a table showing the three most popular items in each of the aisles “baking ingredients”, “dog food care”, and “packaged vegetables fruits”. 

```{r}
instacart %>% 
  filter(aisle %in% c("baking ingredients", "dog food care", "packaged vegetables fruits")) %>%
  group_by(aisle) %>% 
  count(product_name) %>% 
  mutate(rank = min_rank(desc(n))) %>% 
  filter(rank < 4) %>% 
  arrange(desc(n)) %>%
  knitr::kable()
```

Make a table showing the mean hour of the day at which Pink Lady Apples and Coffee Ice Cream are ordered on each day of the week.

```{r message = FALSE}
instacart %>%
  filter(product_name %in% c("Pink Lady Apples", "Coffee Ice Cream")) %>%
  group_by(product_name, order_dow) %>%
  summarize(mean_hour = mean(order_hour_of_day)) %>%
  spread(key = order_dow, value = mean_hour) %>%
  knitr::kable(digits = 2)
```

## Problem 2

Load, tidy, and wrangle the data.

```{r message = FALSE}
accel_df <- 
  read_csv("data/accel_data.csv") %>% 
  janitor::clean_names() %>% 
  pivot_longer(
    activity_1:activity_1440,
    names_prefix = "activity_",
    names_to = "minute",
    values_to = "activity"
  ) %>% 
  mutate(
    minute = as.numeric(minute),
    dow = ifelse(day %in% c('Saturday', 'Sunday'), "weekend", "weekday")
  ) %>% 
  relocate(week, day_id, day, dow)
```

Brief discription of the resulting dataset:

- The data contains `r nrow(accel_df)` rows and `r ncol(accel_df)` columns.

- There are 7 variables in the data set: `week` represents the week number from 1 to 5, `day_id` shows the id of each day ranging from 1 to 35, `day` shows what day of the week it is, `dow` shows whether the day is a weekday or weekend, `minite` represents every minute within a 24-hour day ranging from 1 to 1440, `activity` shows the activity counts for each minute of a 24-hour day starting at midnight, and its min value is ``r min(pull(accel_df, activity))`` and max value is ``r max(pull(accel_df, activity))``.

Analyses of the data focus on the total activity over the day.

```{r message = FALSE}
total_act <- 
  accel_df %>% 
  group_by(week, day) %>% 
  summarize(sum_activity = sum(activity))
```

Create a table showing the totals.

```{r}
total_act %>% 
  pivot_wider(
    names_from = "day",
    values_from = "sum_activity"
  ) %>% 
  relocate(1, 5, 3, 7, 8, 6, 2, 4) %>% 
  knitr::kable(
    caption = "Total activity over a day",
    align = "l"
  )
```

Plot the data to see if there is a trend:

```{r}
total_act %>% 
  mutate(
    day = factor(day, levels = c('Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday'))
  ) %>% 
  ggplot(aes(x = day, y = sum_activity, group = week, color = week)) + 
  geom_point() + 
  geom_line()
```

- From the chart, we can see that the total activity count in five weeks has been fluctuating, and the fluctuations in the forth and fifth weeks are relatively greater. Overall, the total activity number on weekends is relatively lower than on weekdays.

Make a plot to shows the 24-hour activity time courses for each day.

```{r}
accel_df %>% 
  mutate(hour = minute / 60) %>% 
  ggplot(aes(x = hour, y = activity, color = day)) + 
  geom_line(alpha = 0.8) + 
  labs(
    x = "Hours",
    y = "Activity",
    title = "24-hour activity time courses"
  )
```

- From the plot, we can see that the activity counts are much lower from 11:00 pm to 5:00 am in the midnight and early morning, whichcorresponds to the sleep time, and the high activity counts are concentrated from 9:00 am to 12:00 am and 8:00 pm to 10:00 pm. Then a moderate activity counts appears from 4:00 pm to 5:00 pm.

## Problem 3

Load and summary the dataset.

```{r}
data("ny_noaa")
ny_noaa <- ny_noaa %>% 
  mutate(tmin = as.numeric(tmin), 
         tmax = as.numeric(tmax)) %>% 
  as_tibble(ny_noaa)
summary(ny_noaa)
```

Brief description of the dataset:
  
- The data contains `r nrow(ny_noaa)` rows and `r ncol(ny_noaa)` columns.

- The dataset contains following variables: ``r names(ny_noaa)``, and some key variables are: `id` represents the weather station ID, `data` represents the date of observation, `prcp` represents precipitation(tenths of mm), `snow` represents snowfall(mm), `snwd` represents snow depth(mm), `tmax` represents maximum temperature (tenths of degrees C), `tmin` represents minimun temperature(tenths of degrees C).

- The data was collected by `r length(unique(ny_noaa$id))` weather stations from 01/01/1981 to 12/31/2010. By using `summary` function, we can also see that there are lots of missing values in variables: `prcp`, `snow`, `snwd`, `tmax`, `tmin`, and nearly 5.6% of `prcp`, 14.7% of `snow`, 22.8% of `snwd`, and over 40% of `tmin` and `tmax` values are missing. If the missing is not at random, there will be bias in the data and further statistical analysis result will be affected.

Clean the data.

```{r}
ny_noaa <- ny_noaa %>%
  janitor::clean_names() %>%
  separate(date, into = c('year', 'month', 'day'), sep = "-") %>%
  mutate(
    tmax = tmax/10,
    tmin = tmin/10,
    prcp = prcp/10,
    year = as.numeric(year),
    month = as.numeric(month),
    day = as.numeric(day))
```

- We should divide `tmin`, `tmax`, `prcp` by 10 to keep them in  degrees C and mm. Then as we convert `tmin`, `tmax` into numeric before, we will also convert `year`, `month`, `day` into numeric formate. 